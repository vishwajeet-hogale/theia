# Computer Vision and NLP Techniques To Generate Image Captions - Theia
The eyes are a person's primary sense organ. A quick glance around us reveals how visual most of
the information in our surroundings is. Timetables in train stations, signs showing the correct path or
a potential hazard, and a billboard advertising a new product on the market are all examples of visual
information that we see on a regular basis. For the blind and visually challenged, most of this
information is inaccessible, limiting their independence. Our project is a mobile application to help
the visually impaired. It gives a verbal description of one's surroundings, within the scope of the
mobile phoneâ€™s camera.
Image Caption Generator or Photo Descriptions is one of the Applications of Deep Learning. In
Which we must pass the image to the model and the model does some processing and generates
captions or descriptions as per its training. This prediction is not always accurate and generates some
meaningless sentences. We need very high computational power and a very huge dataset for better
results. Now we will see what our project does.

With this project, we hope to achieve an abstract explanation of the surroundings to a visually
impaired person.
Goal:

* Detects all objects from a given picture and generates text captions.
* Verbal description of all the objects in the surroundings of a blind person.

![image](https://github.com/vishwajeet-hogale/theia/assets/69192757/a3c45cd0-72af-4907-a52b-e877086f5b91)

![image](https://github.com/vishwajeet-hogale/theia/assets/69192757/e5e58af2-b230-4865-8920-907cd988deb8)

![image](https://github.com/vishwajeet-hogale/theia/assets/69192757/f0e2e7cd-9fb3-42bc-99f0-ffa6bdd9847b)

![image](https://github.com/vishwajeet-hogale/theia/assets/69192757/aa17c21f-b05f-4aa8-8c1e-93f2920cb461)



